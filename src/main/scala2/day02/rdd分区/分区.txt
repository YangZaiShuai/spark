rdd的分区有几个
就会生成几个task
几个task对数据处理,一个task一个结果文件

如果是通过并行化创建rdd时候
没有指定分区,
分区数量和 集群核数 有关系
默认核数:一个核一个线程,一个县城对应一个Task
task执行业务,如果数据特别多,我有十二个线程,要发挥最大性能
那我就生成12个task最快(--total excutor core 数量一致)

从hdfs读文件,生成的rdd的分区数量?
1.如果只有一个小文件(一个block块),生成的rdd数量 是2(配置:最小分区数量) 不是1
2.若果有俩小文件  生成rdd 两个分区
  若果有仨小文件  生成rdd 三个分区      几个block块,就是几个分区


/**
奇怪
*/
上课测试发生了异常,明明是4文件,却是5个分区
这四个文件 大小分别是 22k 25k  682k  21k
星哥都不会了!!!!!!!!!!!!!!!!
是不是有什么算法??发现某一个文件相对来说比较大??就分成两个分区??

星哥解决!!!
测试
三个文件: 6B 6B  600B
sc.textFile("hdfs://hdp-01:9000/wc")
查看分区  :  4!!!!!不合想象


往hdfs传文件,是物理切分
计算分区:逻辑切分(InputSplit)的时候,多切了一份
sc.textFile("hdfs://hdp-01:9000/wc",1)  这个1代表每个块分区数量
查看分区 :  3   就是想象中的数量

spark里面有允许最小分区的数量这个东西:2
mapreduce允许最小mapper数量是1

100M文件 mapreduce默认启动一个mapperTask就可以了
        spark     启动 两个Task(因为俩分区..最小俩分区)


源代码:







